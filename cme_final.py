# -*- coding: utf-8 -*-
"""cme final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CKRWkNlOiEO7iPUcd1l0hqoWkfu-IHJ6
"""

pip install sunpy astropy parfive beautifulsoup4 lxml zeep drms

pip install reproject

pip install mpl_animators

import os
import random
import shutil
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt

from sunpy.net import Fido, attrs as a
from sunpy.io import read_file
from sunpy.map import Map
import astropy.units as u

# Step 1: Create output directories
os.makedirs("extracted_images", exist_ok=True)

# Step 2: Generate random dates
start_date = datetime(2023, 1, 1)
end_date = datetime(2023, 8, 31)
num_samples = 20

random_dates = sorted([
    start_date + timedelta(days=random.randint(0, (end_date - start_date).days))
    for _ in range(num_samples)
])

meta_data = []

# Step 3: Download + extract + save
for date in tqdm(random_dates, desc="Fetching images"):
    try:
        # Fixed time for each date
        date = date.replace(hour=12, minute=0, second=0)
        start_time = date.strftime('%Y-%m-%dT%H:%M:%S')
        end_time = (date + timedelta(hours=2)).strftime('%Y-%m-%dT%H:%M:%S')

        # Search for AIA 171 Å image
        result = Fido.search(
            a.Time(start_time, end_time),
            a.Instrument.aia,
            a.Wavelength(171 * u.angstrom)
        )

        if len(result) == 0 or result.file_num == 0:
            print(f"No image found at {start_time}")
            continue

        # Download first available image
        downloaded = Fido.fetch(result[0, 0])
        fits_file = downloaded[0]

        # Read the FITS file
        smap = Map(fits_file)
        header = smap.meta

        # Convert image data to 8-bit for PNG
        image_data = smap.data
        image_data = np.nan_to_num(image_data)  # remove NaNs
        norm_data = (255 * (image_data - np.min(image_data)) / (np.ptp(image_data))).astype(np.uint8)

        # Save PNG
        filename_base = os.path.splitext(os.path.basename(fits_file))[0]
        png_path = f"extracted_images/{filename_base}.png"
        plt.imsave(png_path, norm_data, cmap='gray')

        # Store metadata
        meta_data.append({
            "date_obs": header.get("date-obs", ""),
            "wavelength": header.get("wavelnth", ""),
            "exposure_time": header.get("exptime", ""),
            "instrument": header.get("instrume", ""),
            "telescope": header.get("telescop", ""),
            "detector": header.get("detector", ""),
            "obs_type": header.get("obstype", ""),
            "x_scale": header.get("cdelt1", ""),
            "y_scale": header.get("cdelt2", ""),
            "obs_title": header.get("obs_id", ""),
            "image_path": png_path
        })

    except Exception as e:
        print(f"Error on {date}: {e}")

# Step 4: Save metadata to CSV
df = pd.DataFrame(meta_data)
df.to_csv("aia_images_metadata.csv", index=False)
print("✅ All images saved to 'extracted_images/' and metadata to 'aia_images_metadata.csv'")

import shutil
import os
from pathlib import Path
import sunpy

# Step 1: Get SunPy cache path programmatically (works on any OS)
sunpy_cache_path = Path(sunpy.config.get('downloads', 'download_dir')).expanduser()

# Step 2: Set your destination folder
destination_path = Path("aia_fits_files")
destination_path.mkdir(exist_ok=True)

# Step 3: Copy all .fits files
fits_files = list(sunpy_cache_path.rglob("*.fits"))
print(f"Total FITS files found: {len(fits_files)}")

for file in fits_files:
    try:
        shutil.copy(file, destination_path / file.name)
    except Exception as e:
        print(f"Error copying {file.name}: {e}")

print(f"✅ All FITS files copied to '{destination_path}/'")

import sunpy.map
import sunpy
from pathlib import Path
import matplotlib.pyplot as plt

# Step 1: Locate SunPy cache folder
fits_dir = Path(sunpy.config.get('downloads', 'download_dir')).expanduser()

# Step 2: Set output directory
output_dir = Path("converted_frames")
output_dir.mkdir(exist_ok=True)

# Step 3: Find all FITS files
fits_files = sorted(fits_dir.rglob("*.fits"))
print(f"Total FITS files found: {len(fits_files)}")

# Step 4: Convert to PNG
for i, fits_file in enumerate(fits_files):
    try:
        aia_map = sunpy.map.Map(fits_file)

        fig = plt.figure(figsize=(6, 6))
        aia_map.plot()
        plt.axis('off')
        plt.tight_layout()

        png_filename = output_dir / f"frame_{i:03d}.png"
        plt.savefig(png_filename, bbox_inches='tight', pad_inches=0)
        plt.close(fig)

        print(f"✅ Saved: {png_filename}")

    except Exception as e:
        print(f"❌ Error with {fits_file.name}: {e}")

import numpy as np
import cv2
from astropy.io import fits
from glob import glob
from sklearn.preprocessing import MinMaxScaler
from pathlib import Path
import sunpy

# Step 1: Get SunPy cache path
fits_dir = Path(sunpy.config.get('downloads', 'download_dir')).expanduser()
files = sorted([str(f) for f in fits_dir.rglob("*.fits")])

print(f"Total FITS files found: {len(files)}")

# Step 2: Preprocess
images = []

for file in files:
    try:
        with fits.open(file) as hdul:
            # AIA image usually in 2nd HDU
            data = hdul[1].data if len(hdul) > 1 else hdul[0].data

        # Handle NaNs
        data = np.nan_to_num(data)

        # Normalize 0–1
        data_scaled = MinMaxScaler().fit_transform(data)

        # Resize to 224x224
        resized = cv2.resize(data_scaled, (224, 224))
        images.append(resized)

    except Exception as e:
        print(f"❌ Error loading {file}: {e}")

# Final array
images = np.array(images)
images = images[..., np.newaxis]  # Add channel dimension for CNN

print("✅ Loaded and preprocessed:", images.shape)

# CNN Feature Extraction
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten

input_layer = Input(shape=(224, 224, 1))
x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)
x = MaxPooling2D((2, 2))(x)
x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D((2, 2))(x)
x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D((2, 2))(x)
x = Flatten()(x)

cnn_model = Model(inputs=input_layer, outputs=x)
features = cnn_model.predict(images)
print(" Features extracted:", features.shape)

# Dimensionality Reduction using PCA
from sklearn.decomposition import PCA

# Set n_components to a value less than or equal to the number of samples (19)
# For example, setting it to the minimum of samples and features
pca = PCA(n_components=min(features.shape[0], features.shape[1]))
features_reduced = pca.fit_transform(features)
print("Features after PCA:", features_reduced.shape)

# KMeans Clustering (Unsupervised)
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

kmeans = KMeans(n_clusters=3, random_state=42)
cluster_labels = kmeans.fit_predict(features_reduced)
print(" Cluster labels assigned:", np.unique(cluster_labels))

# Visualize a few from each cluster
for cluster in range(3):
    fig, axes = plt.subplots(1, 5, figsize=(15, 3))
    idxs = np.where(cluster_labels == cluster)[0][:5]
    for i, idx in enumerate(idxs):
        axes[i].imshow(images[idx].squeeze(), cmap='gray')
        axes[i].set_title(f"Cluster {cluster}")
        axes[i].axis('off')
    plt.suptitle(f"Samples from Cluster {cluster}")
    plt.show()

# Manually Assign Cluster Labels
# Cluster 0 → No Event → label 0
# Cluster 1 → Flare     → label 1
# Cluster 2 → CME       → label 2
cluster_to_label = {0: 0, 1: 1, 2: 2}
y_labels = np.array([cluster_to_label[c] for c in cluster_labels])

# Train a CNN Classifier
import tensorflow.keras
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten
from sklearn.model_selection import train_test_split

# Split data
X_train, X_test, y_train, y_test = train_test_split(images, y_labels, test_size=0.3, random_state=42, stratify=y_labels)
y_train_cat = to_categorical(y_train, num_classes=3)
y_test_cat = to_categorical(y_test, num_classes=3)

# CNN Model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 1)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu', padding='same'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(3, activation='softmax')  # 3 classes
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train_cat, validation_split=0.15, epochs=5, batch_size=8)
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split

# Split data
X_train, X_test, y_train, y_test = train_test_split(images, y_labels, test_size=0.3, random_state=42, stratify=y_labels)
y_train_cat = to_categorical(y_train, num_classes=3)
y_test_cat = to_categorical(y_test, num_classes=3)

# CNN Model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 1)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu', padding='same'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(3, activation='softmax')  # 3 classes
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train_cat, validation_split=0.15, epochs=5, batch_size=8)

# Evaluate on Test Set
loss, acc = model.evaluate(X_test, y_test_cat)
print("Test Accuracy:", acc)

# Predict a New Frame
pred = model.predict(images[:1])  # Example on first image
print("Predicted Class (0=No Event, 1=Flare, 2=CME):", np.argmax(pred))